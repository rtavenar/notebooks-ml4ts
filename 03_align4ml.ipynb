{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"a14263d011e347c29e910e5f0dadc9fe","deepnote_cell_type":"markdown","tags":[]},"source":["# Lab 3: Alignment-based metrics in Machine Learning\n","\n","* Author: Romain Tavenard (@rtavenar)\n","* License: CC-BY-NC-SA\n","\n","A lab session from a course on Machine Learning for Time Series at ENSAI.\n","One can find lecture notes for this course [there](https://rtavenar.github.io/ml4ts_ensai/)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"eaf6105206fb474abd34ac309e476fc6","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2080,"execution_start":1643108236101,"source_hash":"fa32ce97","tags":[]},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tslearn.metrics import dtw, soft_dtw\n","from tslearn.barycenters import dtw_barycenter_averaging, softdtw_barycenter"]},{"cell_type":"markdown","metadata":{"cell_id":"4efa27ba802442ffb84f564855fe21a7","deepnote_cell_type":"markdown","tags":[]},"source":["# Data loading\n","\n","**Question #1.** Using the [`CachedDatasets`](https://tslearn.readthedocs.io/en/stable/gen_modules/datasets/tslearn.datasets.CachedDatasets.html#tslearn.datasets.CachedDatasets)\n","utility from ``tslearn``, load the \"Trace\" time series dataset.\n","What are the dimensions of an array storing a time series dataset?\n","Create a new dataset `X_subset` made of 50 random time series from classes indexed 1 to 3 (`y_train < 4`)\n","in the training set."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c20808d488c64f01b1a47550cfe92e94","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":14,"execution_start":1643108238186,"source_hash":"5af98abd","tags":[]},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"753b4b39c36546f59b6f6f3b3301decc","deepnote_cell_type":"markdown","tags":[]},"source":["# $k$-means clustering\n","\n","**Question #2.** Implement the Lloyd's algorithm for a $k$-means that would use soft-DTW as \n","its base metric.\n","You can rely on ``tslearn`` functions (see imports above) for \"distance\" computations and barycenter\n","estimation.\n","Your function should return both the current assignments and the barycenters.\n","Check that it runs smoothly for a few iterations on `X_subset` (leave quantitative evaluation aside for now)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e3f33252e56848fc9b4290daf5122858","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7,"execution_start":1643108238204,"source_hash":"c04f331d","tags":[]},"outputs":[],"source":["def kmeans_soft_dtw(X, gamma, k, max_iter=10):\n","    n_timeseries, n_timestamps, n_features = X.shape\n","\n","    # Init barycenters at random\n","    barycenters = X[np.random.randint(n_timeseries, size=k)]\n","\n","    for e in range(max_iter):\n","        # Assign a cluster to each time series\n","        assign = np.zeros((n_timeseries, ), dtype=np.int)\n","        # for i in range(n_timeseries):\n","            # TODO\n","            # assign[i] = ...\n","        # Update centroids (barycenters) for each cluster\n","        # for j in range(k):\n","            # TODO\n","            # barycenters[j] = ...\n","    \n","    return assign, barycenters\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"4cf6e1d79ba44b6ea7a5421a8d552e38","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #3.** Implement the Lloyd's algorithm for a $k$-means that would use **DTW** as \n","its base metric.\n","You can rely on ``tslearn`` functions (see imports above) for \"distance\" computations and barycenter\n","estimation.\n","Your function should return both the current assignments and the barycenters.\n","Check that it runs smoothly for a few iteration on `X_subset` (leave quantitative evaluation aside for now)."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6935c867157a41deaa58e8f1388b28ff","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1643108238220,"source_hash":"9ad796c4","tags":[]},"outputs":[],"source":["def kmeans_soft_dtw(X, k, max_iter=10):\n","    n_timeseries, n_timestamps, n_features = X.shape\n","\n","    # Init barycenters at random\n","    barycenters = X[np.random.randint(n_timeseries, size=k)]\n","\n","    for e in range(max_iter):\n","        # Assign a cluster to each time series\n","        assign = np.zeros((n_timeseries, ), dtype=np.int)\n","        # for i in range(n_timeseries):\n","            # TODO\n","            # assign[i] = ...\n","        # Update centroids (barycenters) for each cluster\n","        # for j in range(k):\n","            # TODO\n","            # barycenters[j] = ...\n","    \n","    return assign, barycenters"]},{"cell_type":"markdown","metadata":{"cell_id":"901258a361d74ebea745653eb5b6d19f","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #4.** Implement a function that would assess the quality of a clustering in terms of \n","intra-cluster inertia, computed using **DTW** as the base metric.\n","Your function should take a time series dataset, corresponding assignments and barycenters as inputs."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"14a37175a1044b719ad8d724b7e8edef","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":9,"execution_start":1643108238224,"source_hash":"7b6c583f","tags":[]},"outputs":[],"source":["def dtw_cost(X, assign, barycenters):\n","    n_timeseries, n_timestamps, n_features = X.shape\n","\n","    total_cost = 0.\n","    # TODO\n","    \n","    return total_cost\n"]},{"cell_type":"markdown","metadata":{"cell_id":"2890fd2e533f40e59b7e1d17392f54d9","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #5.** Compare your $k$-means implementations in terms of DTW inertia.\n","For a fair comparison, make sure that they are initialized similarly, by appropriately setting your\n","random number generator seeds.\n","What do you observe? Is that expected / Do you have an explanation for that?"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4d542a44f3854aad9559b2f5fe6e5fb9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1,"execution_start":1643108238276,"source_hash":"4c645b0e","tags":[]},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"4f9010909c26496cb13661f0815ace49","deepnote_cell_type":"markdown","tags":[]},"source":["# Multi-step ahead forecasting\n","\n","In this section, your goal will be to implement a single-hidden-layer perceptron for time series forecasting.\n","Your network will be trained to minimize normalized soft-DTW[^1].\n","\n","To do so, we will rely on a (very nice!) `torch`-compatible implementation of soft-DTW obtained from \n","[github](https://github.com/Maghoumi/pytorch-softdtw-cuda) \n","(the corresponding file is already added to this project).\n","\n","The code below is an implementation of a generic Multi-Layer-Perceptron class in `torch`, and you will rely on it for your implementation of a forecasting MLP with softDTW loss.\n","\n","[^1]: Normalized soft-DTW (also coined soft-DTW divergence) between time series $\\mathbf{x}$ and \n","$\\mathbf{x}^\\prime$ is defined as: \n","$$\\text{soft-DTW}(\\mathbf{x}, \\mathbf{x}^\\prime) - \\frac{1}{2} \\left( \\text{soft-DTW}(\\mathbf{x}, \\mathbf{x}) + \\text{soft-DTW}(\\mathbf{x}^\\prime, \\mathbf{x}^\\prime) \\right)$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"914d8b9253664422a47f80ed0ddc9469","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":0,"execution_start":1643108238277,"source_hash":"cee8162b","tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","class MultiLayerPerceptron(torch.nn.Module):  # No hidden layer here\n","    def __init__(self, layers, loss=None):\n","        # At init, we define our layers\n","        super(MultiLayerPerceptron, self).__init__()\n","        self.layers = layers\n","        if loss is None:\n","            self.loss = torch.nn.MSELoss(reduction=\"none\")\n","        else:\n","            self.loss = loss\n","        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.001)\n","            \n","\n","    def forward(self, X):\n","        # The forward method informs about the forward pass: how one computes outputs of the network\n","        # from the input and the parameters of the layers registered at init\n","        if not isinstance(X, torch.Tensor):\n","            X = torch.Tensor(X)\n","        batch_size = X.size(0)\n","        X_reshaped = torch.reshape(X, (batch_size, -1))  # Manipulations to deal with time series format\n","        output = self.layers(X_reshaped)\n","        return torch.reshape(output, (batch_size, -1, 1))  # Manipulations to deal with time series format\n","    \n","    def fit(self, X, y, max_epochs=10):\n","        # The fit method performs the actual optimization\n","        X_torch = torch.Tensor(X)\n","        y_torch = torch.Tensor(y)\n","\n","        for e in range(max_epochs):\n","            self.optimizer.zero_grad()\n","            # Forward pass\n","            y_pred = self.forward(X_torch)\n","            # Compute Loss\n","            loss = self.loss(y_pred, y_torch).mean()\n","            if e % 20 == 0:\n","                print('Epoch {}: train loss: {}'.format(e, loss.item()))\n","            # Backward pass\n","            loss.backward()\n","            self.optimizer.step()\n","\n","# Example definition of a MLP model using the class above\n","model = MultiLayerPerceptron(\n","    layers=nn.Sequential(\n","        nn.Linear(in_features=150, out_features=256),\n","        nn.ReLU(),\n","        nn.Linear(in_features=256, out_features=3),\n","        nn.ReLU()\n","    )\n",")\n","# model.fit(X, y, max_epochs=100)  # Here one needs to define what X and y are, obviously"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"9789dc68724c4c9889ab4a0071bdb030","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #6.** Take inspiration from the code above to define an MLP class that would allow training\n","a single-hidden-layer model using normalized soft-DTW as a criterion to be optimized.\n","Train your network for 200 epochs on a forecasting task that would consist, given the first 150 elements\n","of a time series, in predicting the next 125 ones."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6b326d3e6191466b86bd840650d9464b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":35,"execution_start":1643108463164,"source_hash":"65506591","tags":[]},"outputs":[],"source":["from soft_dtw_cuda import SoftDTW\n","\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b823e3be23a04d0f84278d0405cf62b7","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #7.** Use the following code block to qualitatively assess quality of your \n","network's predictions.\n","Do not hesitate to change the time series index to visualize the result for different time series."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"af906fb8456042dca6701da816b91edc","deepnote_cell_type":"code","deepnote_output_heights":[252],"deepnote_to_be_reexecuted":true,"execution_millis":161,"execution_start":1611744714466,"source_hash":"5ffba4b7","tags":[]},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","ts_index = 50\n","\n","y_pred = model(X_test[:, :150, 0]).detach().numpy()\n","\n","plt.figure()\n","plt.plot(X_test[ts_index].ravel())\n","plt.plot(np.arange(150, 275), y_pred[ts_index], 'r-')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"cell_id":"3bb3876f6ba94f5989714911e9598018","deepnote_cell_type":"markdown","tags":[]},"source":["# Shapelet models\n","\n","Shapelet models are time series classifiers that rely on the presence/absence of local shapes in \n","time series to make predictions.\n","These models will be presented in more details later in the course, since they can be seen as a variant of \n","shallow convolutional models for time series.\n","\n","In the following, you will train such models (using their \n","[`tslearn` implementation](https://tslearn.readthedocs.io/en/stable/gen_modules/shapelets/tslearn.shapelets.LearningShapelets.html#tslearn.shapelets.LearningShapelets)) \n","and visualize their learned decision boundaries.\n","For the sake of visualization, models made of only 2 local shapes will be learned, and the following \n","function will be used to visualize them:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"512dc03ee2744d2982bbbe6f52d68fcd","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":0,"execution_start":1611744714631,"source_hash":"4b10b5fa","tags":[]},"outputs":[],"source":["from matplotlib import cm\n","\n","def visualize_shapelet_model_2_shapelets(model, X, y):\n","    distances = model.transform(X)\n","\n","    plt.figure()\n","    viridis = cm.get_cmap('viridis', 4)\n","    # Create a scatter plot of the 2D distances for the time series of each class.\n","    for i, yi in enumerate(np.unique(y)):\n","        plt.scatter(distances[y == yi][:, 0],\n","                    distances[y == yi][:, 1],\n","                    color=viridis(i / 3),\n","                    edgecolors='k',\n","                    label='Class {}'.format(yi))\n","\n","    # Create a meshgrid of the decision boundaries\n","    xmin = np.min(distances[:, 0]) - 0.1\n","    xmax = np.max(distances[:, 0]) + 0.1\n","    ymin = np.min(distances[:, 1]) - 0.1\n","    ymax = np.max(distances[:, 1]) + 0.1\n","    xx, yy = np.meshgrid(np.arange(xmin, xmax, (xmax - xmin) / 200), \n","                         np.arange(ymin, ymax, (ymax - ymin) / 200))\n","    \n","    weights, biases = model.get_weights('classification')\n","    Z = []\n","    for x, y in np.c_[xx.ravel(), yy.ravel()]:\n","        Z.append(np.argmax([biases[i] + weights[0][i]*x + weights[1][i]*y\n","                            for i in range(4)]))\n","    Z = np.array(Z).reshape(xx.shape)\n","    plt.contourf(xx, yy, Z / 3, cmap=viridis, alpha=0.25)\n","\n","    plt.legend()\n","    plt.xlabel('$d(\\mathbf{x}, \\mathbf{s}_1)$')\n","    plt.ylabel('$d(\\mathbf{x}, \\mathbf{s}_2)$')\n","    plt.xlim((xmin, xmax))\n","    plt.ylim((ymin, ymax))\n","    plt.title('Distance transformed time series')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"cell_id":"93f7a363147545e883d2fd55997fe42c","deepnote_cell_type":"markdown","tags":[]},"source":["Let us start with a first attempt.\n","The following code snippet defines a model made of 2 shapelets (=local shapes to be learnt) and train\n","them (as well as the corresponding linear decision boundaries) for 500 epochs:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"910ed98a5d1a48b9bc369add9573ac6b","deepnote_cell_type":"code","deepnote_output_heights":[null,21],"deepnote_to_be_reexecuted":true,"execution_millis":11529,"execution_start":1611744714642,"source_hash":"a13255fd","tags":[]},"outputs":[],"source":["from tslearn.shapelets import LearningShapelets\n","\n","shp_clf = LearningShapelets(\n","    n_shapelets_per_size={20: 2},  # 2 shapelets of length 20\n","    max_iter=500,\n","    verbose=0,                     # Do not print information on the evolution of the loss\n","    scale=False,\n","    random_state=42\n",")\n","shp_clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"cell_id":"8c84bf04807b4a69aa8b7ca242c85e6c","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #8.** Visualize the obtained decision boundaries. \n","Would you expect this model to be a decent classifier?"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c408687482e5452abcfbc0f429292aa2","deepnote_cell_type":"code","deepnote_output_heights":[284],"deepnote_to_be_reexecuted":true,"execution_millis":2352,"execution_start":1611744726171,"source_hash":"3791a098","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"187d3956407d4df496de40d7eb0b5c67","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #9.** Shapelet models usually benefit from scaling of the input time series \n","(yet this is, of course, very dataset-specific).\n","See if this helps in our case."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ecc60cc18017497487aaf921bbf77c47","deepnote_cell_type":"code","deepnote_output_heights":[284],"deepnote_to_be_reexecuted":true,"execution_millis":10483,"execution_start":1611744728528,"source_hash":"6b95ed40","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"3d99068386504fb2aebaae1a9c33ea19","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #10.** By default, the `tslearn` implementation uses SGD as an optimizer.\n","See if using `\"adam\"` helps in our case."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"de6a11ca40154c23b15adcee3c3d83c9","deepnote_cell_type":"code","deepnote_output_heights":[284],"deepnote_to_be_reexecuted":true,"execution_millis":10300,"execution_start":1611744739021,"source_hash":"4395b75","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"e8e43d792cb64c22a1580631a078f168","deepnote_cell_type":"markdown","tags":[]},"source":["**Question #11.** Set the learning rate of the Adam optimizer to 1e-2 \n","(you will need to import the `Adam` class from `keras` as follows) and see if this improves the learning."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f2ea9385603b443f9871e849c6bf3b4c","deepnote_cell_type":"code","deepnote_output_heights":[284],"deepnote_to_be_reexecuted":true,"execution_millis":10391,"execution_start":1611744749331,"source_hash":"7204018f","tags":[]},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c5f69e5e83da4132b9c8b319115ffab5","kernelspec":{"display_name":"py38_data","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"25f9a3951446179f6c2016b22a60b44495fe90f43bda7f3caedfe2c1a9cd31f9"}}},"nbformat":4,"nbformat_minor":0}
