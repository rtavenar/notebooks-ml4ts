{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a14263d011e347c29e910e5f0dadc9fe",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Lab 3: Alignment-based metrics in Machine Learning\n",
    "\n",
    "* Author: Romain Tavenard (@rtavenar)\n",
    "* License: CC-BY-NC-SA\n",
    "\n",
    "A lab session from a course on Machine Learning for Time Series at ENSAI.\n",
    "One can find lecture notes for this course [there](https://rtavenar.github.io/ml4ts_ensai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "eaf6105206fb474abd34ac309e476fc6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2080,
    "execution_start": 1643108236101,
    "source_hash": "fa32ce97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tslearn.metrics import dtw, soft_dtw\n",
    "from tslearn.barycenters import dtw_barycenter_averaging, softdtw_barycenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4efa27ba802442ffb84f564855fe21a7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Data loading\n",
    "\n",
    "**Question #1.** Using the [`CachedDatasets`](https://tslearn.readthedocs.io/en/stable/gen_modules/datasets/tslearn.datasets.CachedDatasets.html#tslearn.datasets.CachedDatasets)\n",
    "utility from ``tslearn``, load the \"Trace\" time series dataset.\n",
    "What are the dimensions of an array storing a time series dataset?\n",
    "Create a new dataset `X_subset` made of 50 random time series from classes indexed 1 to 3 (`y_train < 4`)\n",
    "in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c20808d488c64f01b1a47550cfe92e94",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1643108238186,
    "source_hash": "5af98abd",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "753b4b39c36546f59b6f6f3b3301decc",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# $k$-means clustering\n",
    "\n",
    "**Question #2.** Implement the Lloyd's algorithm for a $k$-means that would use soft-DTW as \n",
    "its base metric.\n",
    "You can rely on ``tslearn`` functions (see imports above) for \"distance\" computations and barycenter\n",
    "estimation.\n",
    "Your function should return both the current assignments and the barycenters.\n",
    "Check that it runs smoothly for a few iterations on `X_subset` (leave quantitative evaluation aside for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e3f33252e56848fc9b4290daf5122858",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1643108238204,
    "source_hash": "c04f331d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_soft_dtw(X, gamma, k, max_iter=10):\n",
    "    n_timeseries, n_timestamps, n_features = X.shape\n",
    "\n",
    "    # Init barycenters at random\n",
    "    barycenters = X[np.random.randint(n_timeseries, size=k)]\n",
    "\n",
    "    for e in range(max_iter):\n",
    "        # Assign a cluster to each time series\n",
    "        assign = np.zeros((n_timeseries, ), dtype=int)\n",
    "        # for i in range(n_timeseries):\n",
    "            # TODO\n",
    "            # assign[i] = ...\n",
    "        # Update centroids (barycenters) for each cluster\n",
    "        # for j in range(k):\n",
    "            # TODO\n",
    "            # barycenters[j] = ...\n",
    "    \n",
    "    return assign, barycenters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4cf6e1d79ba44b6ea7a5421a8d552e38",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #3.** Implement the Lloyd's algorithm for a $k$-means that would use **DTW** as \n",
    "its base metric.\n",
    "You can rely on ``tslearn`` functions (see imports above) for \"distance\" computations and barycenter\n",
    "estimation.\n",
    "Your function should return both the current assignments and the barycenters.\n",
    "Check that it runs smoothly for a few iteration on `X_subset` (leave quantitative evaluation aside for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6935c867157a41deaa58e8f1388b28ff",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1643108238220,
    "source_hash": "9ad796c4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_soft_dtw(X, k, max_iter=10):\n",
    "    n_timeseries, n_timestamps, n_features = X.shape\n",
    "\n",
    "    # Init barycenters at random\n",
    "    barycenters = X[np.random.randint(n_timeseries, size=k)]\n",
    "\n",
    "    for e in range(max_iter):\n",
    "        # Assign a cluster to each time series\n",
    "        assign = np.zeros((n_timeseries, ), dtype=int)\n",
    "        # for i in range(n_timeseries):\n",
    "            # TODO\n",
    "            # assign[i] = ...\n",
    "        # Update centroids (barycenters) for each cluster\n",
    "        # for j in range(k):\n",
    "            # TODO\n",
    "            # barycenters[j] = ...\n",
    "    \n",
    "    return assign, barycenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "901258a361d74ebea745653eb5b6d19f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #4.** Implement a function that would assess the quality of a clustering in terms of \n",
    "intra-cluster inertia, computed using **DTW** as the base metric.\n",
    "Your function should take a time series dataset, corresponding assignments and barycenters as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "14a37175a1044b719ad8d724b7e8edef",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1643108238224,
    "source_hash": "7b6c583f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dtw_cost(X, assign, barycenters):\n",
    "    n_timeseries, n_timestamps, n_features = X.shape\n",
    "\n",
    "    total_cost = 0.\n",
    "    # TODO\n",
    "    \n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2890fd2e533f40e59b7e1d17392f54d9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #5.** Compare your $k$-means implementations in terms of DTW inertia.\n",
    "For a fair comparison, make sure that they are initialized similarly, by appropriately setting your\n",
    "random number generator seeds.\n",
    "What do you observe? Is that expected / Do you have an explanation for that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4d542a44f3854aad9559b2f5fe6e5fb9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1643108238276,
    "source_hash": "4c645b0e",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4f9010909c26496cb13661f0815ace49",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Multi-step ahead forecasting\n",
    "\n",
    "In this section, your goal will be to implement a single-hidden-layer perceptron for time series forecasting.\n",
    "Your network will be trained to minimize normalized soft-DTW[^1].\n",
    "\n",
    "To do so, we will rely on a `torch`-compatible implementation of soft-DTW [available in `tslearn`](https://tslearn.readthedocs.io/en/stable/gen_modules/metrics/tslearn.metrics.SoftDTWLossPyTorch.html).\n",
    "\n",
    "[^1]: Normalized soft-DTW (also coined soft-DTW divergence) between time series $\\mathbf{x}$ and \n",
    "$\\mathbf{x}^\\prime$ is defined as: \n",
    "$$\\text{soft-DTW}(\\mathbf{x}, \\mathbf{x}^\\prime) - \\frac{1}{2} \\left( \\text{soft-DTW}(\\mathbf{x}, \\mathbf{x}) + \\text{soft-DTW}(\\mathbf{x}^\\prime, \\mathbf{x}^\\prime) \\right)$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9789dc68724c4c9889ab4a0071bdb030",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #6.** Define an MLP model that would allow training\n",
    "a single-hidden-layer model using normalized soft-DTW as a criterion to be optimized.\n",
    "Train your network for 200 epochs on a forecasting task that would consist, given the first 150 elements\n",
    "of a time series, in predicting the next 125 ones. You can use the training loop provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6b326d3e6191466b86bd840650d9464b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 35,
    "execution_start": 1643108463164,
    "source_hash": "65506591",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def train_model(model, X, y, epochs, criterion, optimizer):\n",
    "    dataset = TensorDataset(torch.tensor(X).float(), torch.tensor(y).float())\n",
    "    dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in dataloader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets).mean()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b823e3be23a04d0f84278d0405cf62b7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #7.** Use the following code block to qualitatively assess quality of your \n",
    "network's predictions.\n",
    "Do not hesitate to change the time series index to visualize the result for different time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "af906fb8456042dca6701da816b91edc",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     252
    ],
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 161,
    "execution_start": 1611744714466,
    "source_hash": "5ffba4b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ts_index = 50\n",
    "\n",
    "y_pred = model(torch.tensor(X_test[:, :150]).float()).detach().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X_test[ts_index].ravel())\n",
    "plt.plot(np.arange(150, 275), y_pred[ts_index], 'r-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "c5f69e5e83da4132b9c8b319115ffab5",
  "kernelspec": {
   "display_name": "py3.10_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
